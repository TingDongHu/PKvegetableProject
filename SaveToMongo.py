import pandas as pd
from pymongo import MongoClient
from datetime import datetime, date
import traceback
from tqdm import tqdm
import re

# é…ç½®ä¿¡æ¯
CSV_FILE = 'xinfadi_prices_selenium.csv'
MONGODB_URI = "mongodb://DBadmin:DBpwd@127.0.0.1:27017/admin"
DB_NAME = "xinfadi"
COLLECTION_NAME = "prices"
BATCH_SIZE = 1000  # æ¯æ‰¹æ’å…¥çš„æ•°æ®é‡


def clean_price(price_str):
    """æ¸…æ´—ä»·æ ¼å­—ç¬¦ä¸²å¹¶è½¬ä¸ºæµ®ç‚¹æ•°"""
    if not price_str or pd.isna(price_str):
        return None

    # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼ˆå¦‚ï¿¥ã€$ç­‰ç¬¦å·å’Œä¸­æ–‡å•ä½ï¼‰
    cleaned = re.sub(r'[^\d.]', '', str(price_str))
    try:
        return float(cleaned) if cleaned else None
    except ValueError:
        return None


def clean_date(date_str):
    """æ¸…æ´—æ—¥æœŸå­—ç¬¦ä¸²å¹¶è½¬ä¸ºdatetimeå¯¹è±¡ï¼ˆæ—¶é—´è®¾ä¸º00:00:00ï¼‰"""
    if not date_str or pd.isna(date_str):
        return None

    date_str = str(date_str).strip()

    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        '%Y-%m-%d',  # 2023-07-20
        '%Y/%m/%d',  # 2023/07/20
        '%Yå¹´%mæœˆ%dæ—¥',  # 2023å¹´07æœˆ20æ—¥
        '%m/%d/%Y',  # 07/20/2023
        '%m-%d-%Y'  # 07-20-2023
    ]

    for fmt in date_formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            # å…³é”®ä¿®æ”¹ï¼šè¿”å›datetimeå¯¹è±¡ä½†æ—¶é—´è®¾ä¸º00:00:00
            return datetime(dt.year, dt.month, dt.day)
        except ValueError:
            continue

    return None


def connect_to_mongodb():
    """å»ºç«‹MongoDBè¿æ¥"""
    try:
        print("ğŸ”Œ æ­£åœ¨è¿æ¥MongoDB...")
        client = MongoClient(
            MONGODB_URI,
            serverSelectionTimeoutMS=5000,
            connectTimeoutMS=30000,
            socketTimeoutMS=30000
        )
        client.admin.command('ping')
        db = client[DB_NAME]
        collection = db[COLLECTION_NAME]
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°MongoDB (æ•°æ®åº“: {DB_NAME}, é›†åˆ: {COLLECTION_NAME})")
        return collection
    except Exception as e:
        print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {str(e)}")
        print(f"ğŸ” é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return None


def read_and_clean_csv(file_path):
    """è¯»å–å¹¶æ¸…æ´—CSVæ•°æ®"""
    try:
        print(f"ğŸ“‚ æ­£åœ¨è¯»å–å’Œæ¸…æ´—CSVæ–‡ä»¶: {file_path}")
        chunks = pd.read_csv(
            file_path,
            encoding='utf_8_sig',
            dtype=str,
            keep_default_na=False,
            chunksize=BATCH_SIZE
        )

        cleaned_data = []
        for chunk in tqdm(chunks, desc="æ¸…æ´—æ•°æ®è¿›åº¦"):
            # æ›¿æ¢ç©ºå­—ç¬¦ä¸²ä¸ºNone
            chunk = chunk.replace({'': None})

            # è½¬æ¢ä»·æ ¼å­—æ®µ
            chunk['æœ€ä½ä»·'] = chunk['æœ€ä½ä»·'].apply(clean_price)
            chunk['å¹³å‡ä»·'] = chunk['å¹³å‡ä»·'].apply(clean_price)
            chunk['æœ€é«˜ä»·'] = chunk['æœ€é«˜ä»·'].apply(clean_price)

            # è½¬æ¢æ—¥æœŸå­—æ®µï¼ˆå…³é”®ä¿®æ”¹ï¼šä½¿ç”¨datetimeå¯¹è±¡ï¼‰
            chunk['å‘å¸ƒæ—¥æœŸ'] = chunk['å‘å¸ƒæ—¥æœŸ'].apply(clean_date)

            # è¿‡æ»¤æ‰å®Œå…¨æ— æ•ˆçš„è®°å½•
            chunk = chunk[~(
                    chunk['æœ€ä½ä»·'].isna() &
                    chunk['å¹³å‡ä»·'].isna() &
                    chunk['æœ€é«˜ä»·'].isna() &
                    chunk['å‘å¸ƒæ—¥æœŸ'].isna()
            )]

            cleaned_data.extend(chunk.to_dict('records'))

        print(f"âœ… æˆåŠŸæ¸…æ´— {len(cleaned_data)} æ¡æœ‰æ•ˆè®°å½•")
        return cleaned_data
    except Exception as e:
        print(f"âŒ è¯»å–/æ¸…æ´—CSVå¤±è´¥: {str(e)}")
        print(f"ğŸ” é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return None


def insert_to_mongodb(collection, data):
    """å°†æ¸…æ´—åçš„æ•°æ®æ’å…¥MongoDB"""
    if not data or collection is None:
        print("âš ï¸ æ— æœ‰æ•ˆæ•°æ®æˆ–è¿æ¥æ— æ•ˆ")
        return False

    try:
        print("â³ æ­£åœ¨å‡†å¤‡æ‰¹é‡å¯¼å…¥...")
        total_count = len(data)
        inserted_count = 0
        batch_count = (total_count // BATCH_SIZE) + 1

        with tqdm(total=total_count, desc="å¯¼å…¥è¿›åº¦") as pbar:
            for i in range(batch_count):
                batch = data[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]
                if not batch:
                    continue

                # æ·»åŠ å¯¼å…¥æ—¶é—´æˆ³
                current_time = datetime.now()
                for record in batch:
                    record['import_time'] = current_time

                # æ‰¹é‡æ’å…¥
                result = collection.insert_many(batch)
                inserted_count += len(result.inserted_ids)
                pbar.update(len(batch))

        print(f"ğŸ’¾ æˆåŠŸå¯¼å…¥ {inserted_count}/{total_count} æ¡è®°å½•")

        # åˆ›å»ºä¼˜åŒ–ç´¢å¼•
        print("ğŸ” æ­£åœ¨åˆ›å»ºä¼˜åŒ–ç´¢å¼•...")
        collection.create_index([("å“å", 1)], background=True)
        collection.create_index([("å‘å¸ƒæ—¥æœŸ", 1)], background=True)
        collection.create_index([("æœ€ä½ä»·", 1)], background=True)
        collection.create_index([("å¹³å‡ä»·", 1)], background=True)
        collection.create_index([("æœ€é«˜ä»·", 1)], background=True)
        collection.create_index([("import_time", 1)], background=True)
        print("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        print(f"ğŸ” é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False


def main():
    print("\n" + "=" * 60)
    print("ğŸ“Š CSVæ•°æ®æ¸…æ´—å¯¼å…¥å·¥å…· (MongoDBå…¼å®¹ç‰ˆ)")
    print("=" * 60)

    # 1. è¯»å–å¹¶æ¸…æ´—æ•°æ®
    cleaned_data = read_and_clean_csv(CSV_FILE)
    if cleaned_data is None:
        return

    # 2. è¿æ¥æ•°æ®åº“
    collection = connect_to_mongodb()
    if collection is None:
        return

    # 3. å¯¼å…¥æ•°æ®
    if not insert_to_mongodb(collection, cleaned_data):
        print("âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    else:
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "æ€»è®°å½•æ•°": collection.count_documents({}),
            "æœ‰ä»·æ ¼è®°å½•": collection.count_documents({"æœ€ä½ä»·": {"$exists": True}}),
            "æœ‰æ—¥æœŸè®°å½•": collection.count_documents({"å‘å¸ƒæ—¥æœŸ": {"$exists": True}})
        }
        print("\nğŸ“Š é›†åˆç»Ÿè®¡:")
        for k, v in stats.items():
            print(f"{k}: {v}")

        # éªŒè¯ç¬¬ä¸€æ¡è®°å½•çš„æ—¥æœŸæ ¼å¼
        sample = collection.find_one({}, {"å‘å¸ƒæ—¥æœŸ": 1})
        print(f"\nç¤ºä¾‹æ—¥æœŸæ ¼å¼: {sample['å‘å¸ƒæ—¥æœŸ']} (ç±»å‹: {type(sample['å‘å¸ƒæ—¥æœŸ'])})")

    print("=" * 60)
    print("ğŸ ç¨‹åºæ‰§è¡Œå®Œæ¯•")
    print("=" * 60)


if __name__ == "__main__":
    main()